# ```python
# Import all required packages
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
# ```end

# ```python
# Load the training and test datasets
train_data = pd.read_csv('../../../data/credit-g/credit-g_train.csv')
test_data = pd.read_csv('../../../data/credit-g/credit-g_test.csv')
# ```end

# ```python
# Perform data cleaning and preprocessing
# In this case, we assume that the data is already clean and does not require any additional preprocessing steps.
# ```end

# ```python
# Perform feature processing
# Define the columns to be scaled and encoded
scale_cols = ['num_dependents', 'credit_amount', 'residence_since', 'age', 'installment_commitment', 'duration', 'existing_credits']
encode_cols = ['num_dependents', 'residence_since', 'installment_commitment', 'existing_credits', 'credit_history', 'job', 'housing', 'own_telephone', 'personal_status', 'property_magnitude', 'foreign_worker', 'other_parties', 'other_payment_plans', 'savings_status', 'checking_status', 'employment']

# Define the transformers
scaler = MinMaxScaler()
encoder = OneHotEncoder()

# Define the preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', scaler, scale_cols),
        ('cat', encoder, encode_cols)])

# Fit and transform the training data
train_data = preprocessor.fit_transform(train_data)

# Transform the test data
test_data = preprocessor.transform(test_data)
# ```end

# ```python
# Select the appropriate features and target variables
X_train = train_data.drop(columns=['class'])
y_train = train_data['class']

X_test = test_data.drop(columns=['class'])
y_test = test_data['class']
# ```end

# ```python
# Perform feature selection
# In this case, we assume that all features are relevant and do not drop any columns.
# ```end

# ```python
# Choose the suitable machine learning algorithm or technique (classifier)
# We choose RandomForestClassifier because it is a versatile and widely used classifier that can handle both numerical and categorical data.
clf = RandomForestClassifier()

# Define the pipeline
pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                           ('classifier', clf)])

# Fit the model
pipeline.fit(X_train, y_train)
# ```end

# ```python
# Report evaluation based on only test dataset
# Predict the test data
y_pred = pipeline.predict(X_test)

# Calculate the model accuracy
Accuracy = accuracy_score(y_test, y_pred)

# Calculate the model f1 score
F1_score = f1_score(y_test, y_pred)

# Print the accuracy result
print(f"Accuracy: {Accuracy}")

# Print the f1 score result
print(f"F1_score: {F1_score}")
# ```end