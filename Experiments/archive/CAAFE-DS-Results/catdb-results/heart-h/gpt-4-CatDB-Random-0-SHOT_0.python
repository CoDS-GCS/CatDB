# ```python
# Import all required packages
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
# ```end

# ```python
# Load the datasets
train_data = pd.read_csv('../../../data/heart-h/heart-h_train.csv')
test_data = pd.read_csv('../../../data/heart-h/heart-h_test.csv')
# ```end

# ```python
# Drop the 'ca' column
train_data.drop(columns=['ca'], inplace=True)
test_data.drop(columns=['ca'], inplace=True)
# ```end-dropping-columns

# ```python
# Define a class for dummy encoding
class DummyEncoder(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.columns_ = X.columns
        self.cat_cols_ = X.select_dtypes(include=['object']).columns
        self.non_cat_cols_ = X.columns.drop(self.cat_cols_)
        self.cat_map_ = {col: X[col].unique().tolist() for col in self.cat_cols_}
        self.cat_map_ = {col: [str(i) for i in lst] for col, lst in self.cat_map_.items()}
        return self

    def transform(self, X, y=None):
        return pd.get_dummies(X, columns=self.cat_cols_)

    def inverse_transform(self, trn, y=None):
        trn = trn.copy()
        for col in self.non_cat_cols_:
            trn[col] = trn[col].astype(float)
        return trn
# ```end

# ```python
# Define preprocessing steps
num_cols = ['thalach', 'age', 'trestbps', 'chol', 'oldpeak']
cat_cols = ['chest_pain', 'thal', 'exang', 'fbs', 'sex', 'slope', 'restecg']

num_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler())])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', DummyEncoder())])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)])
# ```end

# ```python
# Define the classifier
classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Combine preprocessing and classifier into a pipeline
model = Pipeline(steps=[('preprocessor', preprocessor),
                        ('classifier', classifier)])
# ```end

# ```python
# Train the model
X_train = train_data.drop('num', axis=1)
y_train = train_data['num']
model.fit(X_train, y_train)
# ```end

# ```python
# Evaluate the model
X_test = test_data.drop('num', axis=1)
y_test = test_data['num']

y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

Train_Accuracy = accuracy_score(y_train, y_train_pred)
Test_Accuracy = accuracy_score(y_test, y_test_pred)

Train_F1_score = f1_score(y_train, y_train_pred, average='weighted')
Test_F1_score = f1_score(y_test, y_test_pred, average='weighted')

print(f"Train_Accuracy:{Train_Accuracy}")
print(f"Train_F1_score:{Train_F1_score}")
print(f"Test_Accuracy:{Test_Accuracy}")
print(f"Test_F1_score:{Test_F1_score}")
# ```end