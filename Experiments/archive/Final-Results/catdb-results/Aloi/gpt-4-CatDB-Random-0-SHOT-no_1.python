# ```python
# Import all required packages
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

# Load the training and test datasets
train_data = pd.read_csv('../../../data/Aloi/Aloi_train.csv')
test_data = pd.read_csv('../../../data/Aloi/Aloi_test.csv')

# Perform feature processing
# Scale numerical columns
scaler = MinMaxScaler()
numerical_cols = ['76','119','114','91','113','15','21','67','38','80','66','31','110','120','34','58','109','55','29','62','89','111','84','6','35','16','124','96','104','123','43','92','75','5','68','73','103','17','57','14','93','98','70','27','30','47','54','116','118','81','41','64','8','3','61','50','44','79','97','51','126','56','60','125','88','53','69','100','63','26','18','78','1','87','25','105','4','86','99','46','13','42','106','90','40','115','7','127','83','39','94','101','9','112','22','2','71','117','33','107','10','20','48','108','11','36','49','28','52','19','23','74','77','32','37','102','122','12','95','24','45','65','72','59','85','0','121','82']
train_data[numerical_cols] = scaler.fit_transform(train_data[numerical_cols])
test_data[numerical_cols] = scaler.transform(test_data[numerical_cols])

# Encode categorical columns
encoder = OneHotEncoder(drop='first')
categorical_cols = ['76','119','114','91','113','15','21','67','38','80','66','31','110','120','34','58','109','55','29','62','89','111','84','6','35','16','124','96','104','123','43','92','75','5','68','73','103','17','57','14','93','98','70','27','30','47','54','116','118','81','41','64','8','3','61','50','44','79','97','51','126','56','60','125','88','53','69','100','63','26','18','78','1','87','25','105','4','86','99','46','13','42','106','90','40','115','7','127','83','39','94','101','9','112','22','2','71','117','33','107','10','20','48','108','11','36','49','28','52','19','23','74','77','32','37','102','122','12','95','24','45','65','72','59','85','0','121','82']
encoder.fit(train_data[categorical_cols])
train_data = pd.get_dummies(train_data, columns=categorical_cols, drop_first=True)
test_data = pd.get_dummies(test_data, columns=categorical_cols, drop_first=True)

# Select the appropriate features and target variables for the question
X_train = train_data.drop(columns=['target'])
y_train = train_data['target']
X_test = test_data.drop(columns=['target'])
y_test = test_data['target']

# Choose the suitable machine learning algorithm or technique (regressor)
# We choose RandomForestRegressor because it is a versatile and widely used algorithm that can handle both numerical and categorical data, and it also has parameters to prevent overfitting.
regressor = RandomForestRegressor(max_leaf_nodes=500)
regressor.fit(X_train, y_train)

# Report evaluation based on train and test dataset
y_train_pred = regressor.predict(X_train)
y_test_pred = regressor.predict(X_test)

Train_R_Squared = r2_score(y_train, y_train_pred)
Train_RMSE = np.sqrt(mean_squared_error(y_train, y_train_pred))
Test_R_Squared = r2_score(y_test, y_test_pred)
Test_RMSE = np.sqrt(mean_squared_error(y_test, y_test_pred))

print(f"Train_R_Squared:{Train_R_Squared}")   
print(f"Train_RMSE:{Train_RMSE}") 
print(f"Test_R_Squared:{Test_R_Squared}")   
print(f"Test_RMSE:{Test_RMSE}") 
# ```