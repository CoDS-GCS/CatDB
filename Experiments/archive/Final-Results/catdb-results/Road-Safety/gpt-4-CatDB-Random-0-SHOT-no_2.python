# Import all required packages
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, log_loss
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

# Load the training and test datasets
train_data = pd.read_csv('../../../data/Road-Safety/Road-Safety_train.csv')
test_data = pd.read_csv('../../../data/Road-Safety/Road-Safety_test.csv')

# Perform data cleaning and preprocessing
# Define columns for imputation and scaling
num_cols = ['1st_Road_Number','Location_Northing_OSGR','2nd_Road_Number','Location_Easting_OSGR','Latitude','Longitude']
cat_cols = ['Local_Authority_(Highway)','Time','Road_Surface_Conditions','Weather_Conditions','Age_of_Casualty','Local_Authority_(District)','Day_of_Week','Skidding_and_Overturning','Casualty_IMD_Decile','Number_of_Casualties','Age_Band_of_Casualty','Vehicle_Type','Accident_Severity','Propulsion_Code','Junction_Control','Towing_and_Articulation','Vehicle_Manoeuvre','Casualty_Home_Area_Type','Junction_Detail','Carriageway_Hazards','Was_Vehicle_Left_Hand_Drive?','Driver_Home_Area_Type','Special_Conditions_at_Site','Engine_Capacity_(CC)','Did_Police_Officer_Attend_Scene_of_Accident','Pedestrian_Crossing-Human_Control','Number_of_Vehicles','1st_Road_Class','1st_Point_of_Impact','Sex_of_Casualty','Pedestrian_Location','Junction_Location','2nd_Road_Class','Age_of_Vehicle','Speed_limit','Urban_or_Rural_Area','Vehicle_Location-Restricted_Lane','Pedestrian_Movement','Age_Band_of_Driver','Road_Type','Hit_Object_in_Carriageway','Light_Conditions','Police_Force','Bus_or_Coach_Passenger','Journey_Purpose_of_Driver','Age_of_Driver','Pedestrian_Road_Maintenance_Worker','Hit_Object_off_Carriageway','Car_Passenger','Pedestrian_Crossing-Physical_Facilities','Vehicle_Leaving_Carriageway','Date']

# Define transformers in a pipeline
num_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)])

# Append classifier to preprocessing pipeline
clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', RandomForestClassifier(max_leaf_nodes=500))])

# Select the appropriate features and target variables for the question
X_train = train_data.drop('Sex_of_Driver', axis=1)
y_train = train_data['Sex_of_Driver']
X_test = test_data.drop('Sex_of_Driver', axis=1)
y_test = test_data['Sex_of_Driver']

# Fit the model
clf.fit(X_train, y_train)

# Report evaluation based on train and test dataset
y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

Train_Accuracy = accuracy_score(y_train, y_train_pred)
Test_Accuracy = accuracy_score(y_test, y_test_pred)

labels = np.unique(np.concatenate((y_train,y_test)))
Train_Log_loss = log_loss(y_train, y_train_pred, labels=labels)
Test_Log_loss = log_loss(y_test, y_test_pred, labels=labels)

print(f"Train_Accuracy:{Train_Accuracy}")   
print(f"Train_Log_loss:{Train_Log_loss}") 
print(f"Test_Accuracy:{Test_Accuracy}")   
print(f"Test_Log_loss:{Test_Log_loss}")