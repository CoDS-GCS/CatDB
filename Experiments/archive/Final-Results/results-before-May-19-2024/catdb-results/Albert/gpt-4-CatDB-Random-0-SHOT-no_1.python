# # ```python
# Import all required packages
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import cross_val_score
# # ```end

# # ```python
# Load the training and test datasets
train_data = pd.read_csv('../../../data/Albert/Albert_train.csv')
test_data = pd.read_csv('../../../data/Albert/Albert_test.csv')
# # ```end

# # ```python
# Perform data cleaning and preprocessing
# Impute missing values for numerical columns
num_cols = ['V5','V37','V58','V44','V17','V34','V16','V25','V55','V39','V29','V57']
num_imputer = SimpleImputer(strategy='mean')
train_data[num_cols] = num_imputer.fit_transform(train_data[num_cols])
test_data[num_cols] = num_imputer.transform(test_data[num_cols])

# Impute missing values for categorical columns
cat_cols = ['V51','V6','V8','V72','V53','V52','V71','V35','V38','V1','V42','V3','V64','V11','V43','V33','V32','V13','V47','V69','V75','V41','V67','V9','V19','V12','V70','V7','V40','V4','V59','V10','V50']
cat_imputer = SimpleImputer(strategy='most_frequent')
train_data[cat_cols] = cat_imputer.fit_transform(train_data[cat_cols])
test_data[cat_cols] = cat_imputer.transform(test_data[cat_cols])
# # ```end

# # ```python
# Perform feature processing
# Scale numerical columns
num_scaler = MinMaxScaler()
train_data[num_cols] = num_scaler.fit_transform(train_data[num_cols])
test_data[num_cols] = num_scaler.transform(test_data[num_cols])

# One-hot encode categorical columns
cat_encoder = OneHotEncoder(handle_unknown='ignore')
train_data = pd.concat([train_data, pd.DataFrame(cat_encoder.fit_transform(train_data[cat_cols]).toarray())], axis=1)
test_data = pd.concat([test_data, pd.DataFrame(cat_encoder.transform(test_data[cat_cols]).toarray())], axis=1)
train_data.drop(columns=cat_cols, inplace=True)
test_data.drop(columns=cat_cols, inplace=True)
# # ```end

# # ```python
# Select the appropriate features and target variables for the question
X_train = train_data.drop(columns=['class'])
y_train = train_data['class']
X_test = test_data.drop(columns=['class'])
y_test = test_data['class']
# # ```end

# # ```python
# Choose the suitable machine learning algorithm or technique (classifier)
# RandomForestClassifier is selected because it is a versatile and widely used algorithm that can handle both numerical and categorical data, and it also has methods for balancing error in class populations.
clf = RandomForestClassifier(max_leaf_nodes=500)
clf.fit(X_train, y_train)
# # ```end

# # ```python
# Report evaluation based on train and test dataset
y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

Train_Accuracy = accuracy_score(y_train, y_train_pred)
Test_Accuracy = accuracy_score(y_test, y_test_pred)

Train_F1_score = f1_score(y_train, y_train_pred)
Test_F1_score = f1_score(y_test, y_test_pred)

print(f"Train_Accuracy:{Train_Accuracy}")
print(f"Train_F1_score:{Train_F1_score}")
print(f"Test_Accuracy:{Test_Accuracy}")
print(f"Test_F1_score:{Test_F1_score}")
# # ```end