SYSTEM MESSAGE:
###  Task: Select the appropriate features and target variables for the question (Feature Engineering Task). Additional columns add new semantic information, additional columns that are useful for a downstream algorithmpredicting "Delay". They can e.g. be feature combinations, transformations, aggregations where the new column is a function of the existing columns. Use appropriate scale factor for columns are needto transfer.
###  Input: first draft version of pipline with a Data Preprocessing task enclosed in "<CODE> pipline code will be here. </CODE>", and a schema that describes the columns and data types of the dataset, and a data profiling info that summarizes the statistics and quality of the dataset.
###  Output: A modified Python 3.10 code with additional feature enginnering tasks that performs the following steps:
#1 : The target feature in the dataset is "Delay".
#2 : Perform drops columns, if these may be redundant and hurt the predictive performance of the downstream classifier (Feature selection). Dropping columns may help as the chance of overfitting is lower, especially if the dataset is small. The Delay will be trained on the dataset with the generated columns and evaluated on a holdout set.
#3 : If the question is not relevant to the dataset or the task, the output should be: "Insufficient information."
#4 : Don't display the first few rows of the datasets.
#5 : Each codeblock ends with "```end" and starts with "```python".
#6 : Don't use "if __name__ == '__main__':" style, use only flat mode.
---------------------------------------
PROMPT TEXT:
###  Description of the dataset:

Airlines Dataset Inspired in the regression dataset from Elena Ikonomovska. The task is to predict whether a given flight will be delayed, given the information of the scheduled departure.


### <CODE>
# ```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

train_data = pd.read_csv("../../../data/Airlines/Airlines_train.csv")
test_data = pd.read_csv("../../../data/Airlines/Airlines_test.csv")

categorical_features = ["DayOfWeek", "Airline"]
numerical_features = ["AirportTo", "AirportFrom", "Flight", "Length", "Time"]

numerical_transformer = Pipeline(steps=[])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor)
])
# ```end
</CODE>

### Schema, and Data Profiling Info:
"""
# DayOfWeek (int), categorical-values [2,3,0,6,5,4,1]
# AirportTo (int), distinct-count [190], min-value [0.0], max-value [284.0], median-value [25.0], mean-value [43.102]
# Airline (int), categorical-values [0,2,14,7,5,17,4,15,11,1,10,12,13,16,3,9,8,6]
# AirportFrom (int), distinct-count [187], min-value [0.0], max-value [282.0], median-value [65.0], mean-value [76.21]
# Flight (int), distinct-count [1611], min-value [1.0], max-value [7801.0], median-value [1859.5], mean-value [2457.833]
# Length (int), distinct-count [288], min-value [26.0], max-value [420.0], median-value [116.0], mean-value [131.197]
# Time (int), distinct-count [520], min-value [15.0], max-value [1431.0], median-value [786.0], mean-value [795.0555]
# Delay (bool, **This is a target column**), categorical-values [1,0]
"""

### Encode categorical values by "on-hot-encoder" for the following columns:
	# Columns: DayOfWeek,Airline,Delay

### Dataset Attribute:
# Number of samples (rows) in training dataset: 2000

### Question: Provide a pipeline code that modify the Data Preprocessing code by adding Feature Engineering tasks in a multi-threaded environment.