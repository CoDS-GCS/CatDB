# ```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from multiprocessing import Pool

train_data = pd.read_csv("../../../data/Breast-w/Breast-w_train.csv")
test_data = pd.read_csv("../../../data/Breast-w/Breast-w_test.csv")

categorical_features = ['Normal_Nucleoli', 'Bland_Chromatin', 'Clump_Thickness',
                        'Cell_Shape_Uniformity', 'Bare_Nuclei', 'Cell_Size_Uniformity',
                        'Marginal_Adhesion', 'Mitoses', 'Single_Epi_Cell_Size', 'Class']

encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

preprocessor = ColumnTransformer(
    transformers=[('cat', encoder, categorical_features)],
    remainder='passthrough'
)

pipeline = Pipeline([
    ('preprocessor', preprocessor)
])


def process_data(data):
    """
    Applies the data preprocessing pipeline to a given dataset.

    Args:
        data (pd.DataFrame): The dataset to preprocess.

    Returns:
        pd.DataFrame: The preprocessed dataset.
    """
    return pipeline.fit_transform(data)


with Pool() as pool:
    # Apply data preprocessing in parallel for train and test data
    train_data_processed, test_data_processed = pool.map(process_data, [train_data, test_data])
# ```end