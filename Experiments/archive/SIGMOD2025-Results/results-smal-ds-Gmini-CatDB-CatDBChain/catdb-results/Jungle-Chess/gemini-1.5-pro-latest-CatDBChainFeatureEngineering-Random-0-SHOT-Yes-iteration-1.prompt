SYSTEM MESSAGE:
###  Task: Select the appropriate features and target variables for the question (Feature Engineering Task). Additional columns add new semantic information, additional columns that are useful for a downstream algorithmpredicting "class". They can e.g. be feature combinations, transformations, aggregations where the new column is a function of the existing columns. Use appropriate scale factor for columns are needto transfer.
###  Input: first draft version of pipline with a Data Preprocessing task enclosed in "<CODE> pipline code will be here. </CODE>", and a schema that describes the columns and data types of the dataset, and a data profiling info that summarizes the statistics and quality of the dataset.
###  Output: A modified Python 3.10 code with additional feature enginnering tasks that performs the following steps:
#1 : The target feature in the dataset is "class".
#2 : Perform drops columns, if these may be redundant and hurt the predictive performance of the downstream classifier (Feature selection). Dropping columns may help as the chance of overfitting is lower, especially if the dataset is small. The class will be trained on the dataset with the generated columns and evaluated on a holdout set.
#3 : If the question is not relevant to the dataset or the task, the output should be: "Insufficient information."
#4 : Don't display the first few rows of the datasets.
#5 : Each codeblock ends with "```end" and starts with "```python".
#6 : Don't use "if __name__ == '__main__':" style, use only flat mode.
---------------------------------------
PROMPT TEXT:
###  Description of the dataset:


 Description 



This dataset is part of a collection datasets based on the game "Jungle Chess" (a.k.a. Dou Shou Qi). For a description of the rules, please refer to the paper (link attached). The paper also contains a description of various constructed features. As the tablebases are a disjoint set of several tablebases based on which (two) pieces are on the board, we have uploaded all tablebases that have explicit different content:

* Rat vs Rat
* Rat vs Panther
* Rat vs. Lion
* Rat vs. Elephant
* Panther vs. Lion
* Panther vs. Elephant
* Tiger vs. Lion
* Lion vs. Lion
* Lion vs. Elephant
* Elephant vs. Elephant
* Complete (Combination of the above)
* RAW Complete (Combination of the above, containing for both pieces just the rank, file and strength information). This dataset contains a similar classification problem as, e.g., the King and Rook vs. King problem and is suitable for classification tasks. 

(Note that this dataset is one of the above mentioned datasets). Additionally, note that several subproblems are very similar. Having seen a given positions from one of the tablebases arguably gives a lot of information about the outcome of the same position in the other tablebases. 

J. N. van Rijn and J. K. Vis, Endgame Analysis of Dou Shou Qi. ICGA Journal 37:2, 120--124, 2014. ArXiv link: https://arxiv.org/abs/1604.07312


### <CODE>
# ```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

categorical_features = ['black_piece0_file', 'white_piece0_strength', 'black_piece0_strength',
                        'black_piece0_rank', 'white_piece0_rank', 'white_piece0_file']

encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

preprocessor = ColumnTransformer(
    transformers=[('cat', encoder, categorical_features)],
    remainder='passthrough'
)

pipeline = Pipeline([
    ('preprocessor', preprocessor)
])

train_data = pd.read_csv("../../../data/Jungle-Chess/Jungle-Chess_train.csv")
test_data = pd.read_csv("../../../data/Jungle-Chess/Jungle-Chess_test.csv")

X_train = train_data.drop('class', axis=1)
y_train = train_data['class']
X_test = test_data.drop('class', axis=1)
y_test = test_data['class']

X_train_transformed = pipeline.fit_transform(X_train)

X_test_transformed = pipeline.transform(X_test)
# ```end
</CODE>

### Schema, and Data Profiling Info:
"""
# black_piece0_file (int), categorical-values [0,5,2,6,1,3,4]
# white_piece0_strength (int), categorical-values [7,0,5,4,6]
# black_piece0_strength (int), categorical-values [4,0,6,7,5]
# black_piece0_rank (int), categorical-values [1,4,6,7,0,2,8,5,3]
# white_piece0_rank (int), categorical-values [2,0,3,1,4,5,7,6,8]
# white_piece0_file (int), categorical-values [1,5,4,6,2,0,3]
# class (int, **This is a target column**), categorical-values [2,0,1]
"""

### Encode categorical values by "on-hot-encoder" for the following columns:
	# Columns: black_piece0_file,white_piece0_strength,black_piece0_strength,black_piece0_rank,white_piece0_rank,class,white_piece0_file

### Dataset Attribute:
# Number of samples (rows) in training dataset: 2000

### Question: Provide a pipeline code that modify the Data Preprocessing code by adding Feature Engineering tasks in a multi-threaded environment.