# ```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

categorical_features = ['L', 'uniq_Op', 'v(g)', 'ev(g)', 'iv(G)', 'lOComment', 'locCodeAndComment', 'lOBlank']
numerical_features = ['I', 'B', 'uniq_Opnd', 'E', 'N', 'loc', 'total_Opnd', 'total_Op', 'V', 'T', 'branchCount', 'D', 'lOCode']

train_data = pd.read_csv("../../../data/PC1/PC1_train.csv")
test_data = pd.read_csv("../../../data/PC1/PC1_test.csv")

preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median'))
        ]), numerical_features),
        ('cat', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features)
    ])
# ```end
# ```python
from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import numpy as np

model = MultiOutputClassifier(RandomForestClassifier(random_state=42))

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', model)
])
# ```end
# ```python
from joblib import Parallel, delayed

n_jobs = -1  # Use all available cores

def evaluate_model(pipeline, X, y):
    scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')
    return scores.mean()

results = Parallel(n_jobs=n_jobs)(delayed(evaluate_model)(pipeline, train_data.drop('defects', axis=1), train_data['defects']) for _ in range(5))

print(f"Average accuracy: {np.mean(results)}")
# ```end