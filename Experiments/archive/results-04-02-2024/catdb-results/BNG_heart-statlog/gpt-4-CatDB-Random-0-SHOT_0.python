# ```python
# Import all required packages
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
# ```end

# ```python
# Load the training and test datasets
train_data = pd.read_csv('../../../data/BNG_heart-statlog/BNG_heart-statlog_train.csv')
test_data = pd.read_csv('../../../data/BNG_heart-statlog/BNG_heart-statlog_test.csv')
# ```end

# ```python
# Perform data cleaning and preprocessing
# Here we assume that the data is already clean and does not contain any missing or incorrect values.
# If this is not the case, additional steps would be needed here to clean the data.
# ```end

# ```python
# Perform feature processing
# Define the columns to be scaled and encoded
scale_cols = ['thal', 'resting_electrocardiographic_results', 'number_of_major_vessels', 'slope', 'age', 'resting_blood_pressure', 'maximum_heart_rate_achieved', 'oldpeak', 'serum_cholestoral', 'chest']
encode_cols = ['thal', 'resting_electrocardiographic_results', 'number_of_major_vessels', 'slope', 'fasting_blood_sugar', 'exercise_induced_angina', 'sex']

# Define the preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), scale_cols),
        ('cat', OneHotEncoder(), encode_cols)])

# Fit and transform the training data
train_data = preprocessor.fit_transform(train_data)

# Transform the test data
test_data = preprocessor.transform(test_data)
# ```end

# ```python
# Select the appropriate features and target variables
X_train = train_data.drop(columns=['class'])
y_train = train_data['class']

X_test = test_data.drop(columns=['class'])
y_test = test_data['class']
# ```end

# ```python
# Choose the suitable machine learning algorithm or technique (classifier)
# We choose RandomForestClassifier because it is a versatile and powerful algorithm that can handle both numerical and categorical data, and it also has features importance which can be useful for feature selection.
clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)

# Fit the model
clf.fit(X_train, y_train)
# ```end

# ```python
# Report evaluation based on train and test dataset
y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

Train_Accuracy = accuracy_score(y_train, y_train_pred)
Test_Accuracy = accuracy_score(y_test, y_test_pred)

Train_F1_score = f1_score(y_train, y_train_pred, average='weighted')
Test_F1_score = f1_score(y_test, y_test_pred, average='weighted')

print(f"Train_Accuracy:{Train_Accuracy}")
print(f"Train_F1_score:{Train_F1_score}")
print(f"Test_Accuracy:{Test_Accuracy}")
print(f"Test_F1_score:{Test_F1_score}")
# ```end